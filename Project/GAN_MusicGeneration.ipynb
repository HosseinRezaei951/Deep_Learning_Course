{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_MusicGeneration.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfn6qnkBhMfI",
        "outputId": "ea9decff-7085-4f51-ca78-d5c28c61cf94"
      },
      "source": [
        "!pip install mido"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mido\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/6d/e18a5b59ff086e1cd61d7fbf943d86c5f593a4e68bfc60215ab74210b22b/mido-1.2.10-py2.py3-none-any.whl (51kB)\n",
            "\r\u001b[K     |██████▍                         | 10kB 24.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 40kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n",
            "\u001b[?25hInstalling collected packages: mido\n",
            "Successfully installed mido-1.2.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5nntMVWhwg7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55846ff5-5a4a-4d70-8776-93411d4c87be"
      },
      "source": [
        "import os, sys, mido\n",
        "import numpy as np\n",
        "from random import randrange\n",
        "from mido import MidiFile, MidiTrack, Message\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Bidirectional, LSTM, Reshape, RepeatVector, TimeDistributed\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def note_reg(note):\n",
        "    C = [0, 12, 24, 36, 48, 60, 72, 84, 96, 108, 120]\n",
        "    C_sharp = [1, 13, 25, 37, 49, 61, 73, 85, 97, 109, 121]\n",
        "    D = [2, 14, 26, 38, 50, 62, 74, 86, 98, 110, 122]\n",
        "    D_sharp = [3, 15, 27, 39, 51, 63, 75, 87, 99, 111, 123]\n",
        "    E = [4, 16, 28, 40, 52, 64, 76, 88, 100, 112, 124]\n",
        "    F = [5, 17, 29, 41, 53, 65, 77, 89, 101, 113, 125]\n",
        "    F_sharp = [6, 18, 30, 42, 54, 66, 78, 90, 102, 114, 126]\n",
        "    G = [7, 19, 31, 43, 55, 67, 79, 91, 103, 115, 127]\n",
        "    G_sharp = [8, 20, 32, 44, 56, 68, 80, 92, 104, 116]\n",
        "    A = [9, 21, 33, 45, 57, 69, 81, 93, 105, 117]\n",
        "    A_sharp = [10, 22, 34, 46, 58, 70, 82, 94, 106, 118]\n",
        "    B = [11, 23, 35, 47, 59, 71, 83, 95, 107, 119]\n",
        "    if (note in C):\n",
        "        return 0\n",
        "    elif(note in C_sharp):\n",
        "        return 1\n",
        "    elif(note in D):\n",
        "        return 2\n",
        "    elif(note in D_sharp):\n",
        "        return 3\n",
        "    elif(note in E):\n",
        "        return 4\n",
        "    elif(note in F):\n",
        "        return 5\n",
        "    elif(note in F_sharp):\n",
        "        return 6\n",
        "    elif(note in G):\n",
        "        return 7\n",
        "    elif(note in G_sharp):\n",
        "        return 8\n",
        "    elif(note in A):\n",
        "        return 9\n",
        "    elif(note in A_sharp):\n",
        "        return 10\n",
        "    elif(note in B):\n",
        "        return 11\n",
        "    else:\n",
        "        return 'fail'\n",
        "\n",
        "\n",
        "def read_inputFiles(inputPath, dataPath):\n",
        "  paths = []\n",
        "  songs = []\n",
        "  for r, d, f in os.walk(inputPath):\n",
        "      for file in f:\n",
        "          if '.mid' in file:\n",
        "              paths.append(os.path.join(r, file))\n",
        "\n",
        "  for path in paths:\n",
        "      mid = MidiFile(path, type = 1)\n",
        "      songs.append(mid)\n",
        "\n",
        "  notes = []\n",
        "  dataset = []\n",
        "  x = []\n",
        "\n",
        "  #for each in midi object in list of songs\n",
        "  for i in range(len(songs)):\n",
        "      #for each note in midi object\n",
        "      for msg in songs[i]:\n",
        "          #filtering out meta messages\n",
        "          if not msg.is_meta:\n",
        "              #filtering out control changes\n",
        "              if (msg.type == 'note_on'):\n",
        "                  #normalizing note and velocity values\n",
        "                  notes.append([note_reg(msg.note)/11])\n",
        "      for i in range(1, len(notes)):\n",
        "          x.append(notes[i])\n",
        "          if (i >15):\n",
        "              dataset.append(x)\n",
        "              x = x[1:]\n",
        "      x = []\n",
        "      notes = []\n",
        "\n",
        "  dataset = np.array(dataset)\n",
        "  np.save(dataPath, dataset)\n",
        "\n",
        "\n",
        "def load_data(dataPath):\n",
        "  x_train = np.load(dataPath, allow_pickle=True)\n",
        "  x_train = x_train.reshape(len(x_train),4,4)\n",
        "  return x_train\n",
        "\n",
        "\n",
        "class GAN():\n",
        "  def __init__(self):\n",
        "    # Input shape\n",
        "    self.img_rows = 4\n",
        "    self.img_cols = 4\n",
        "    self.img_shape = (self.img_rows, self.img_cols)\n",
        "    self.latent_dim = 16\n",
        "\n",
        "    optimizer = Adam(0.0001, 0.4)\n",
        "\n",
        "    # Build and compile the discriminator\n",
        "    self.discriminator = self.build_discriminator()\n",
        "    self.discriminator.compile(loss='binary_crossentropy',\n",
        "        optimizer=optimizer,\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "    # Build the generator\n",
        "    self.generator = self.build_generator()\n",
        "\n",
        "    # The generator takes noise as input and generates imgs\n",
        "    z = Input(shape=(4,4))\n",
        "    img = self.generator(z)\n",
        "\n",
        "    # For the combined model we will only train the generator\n",
        "    self.discriminator.trainable = False\n",
        "\n",
        "    # The discriminator takes generated images as input and determines validity\n",
        "    valid = self.discriminator(img)\n",
        "\n",
        "    # The combined model  (stacked generator and discriminator)\n",
        "    # Trains the generator to fool the discriminator\n",
        "    self.combined = Model(z, valid)\n",
        "    self.combined.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "\n",
        "  def build_generator(self):\n",
        "\n",
        "    model = Sequential()\n",
        "    #encoder\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(4, 4)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Bidirectional(LSTM(128)))\n",
        "    model.add(Dropout(0.2))\n",
        "    #specifying output to have 16 timesteps\n",
        "    model.add(RepeatVector(16))\n",
        "    #decoder\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(TimeDistributed(Dense(256)))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(TimeDistributed(Dense(1)))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=(4,4))\n",
        "    img = model(noise)\n",
        "\n",
        "    return Model(noise, img)\n",
        "\n",
        "  def build_discriminator(self):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=(16, 1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Bidirectional(LSTM(256)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(RepeatVector(1))\n",
        "    model.add(TimeDistributed(Dense(300)))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(TimeDistributed(Dense(300)))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(TimeDistributed(Dense(300)))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(TimeDistributed(Dense(1)))\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=(16,1))\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)\n",
        "  \n",
        "\n",
        "  def train(self, dataPath, modelPath, epochs, batch_size=128, save_interval=50):\n",
        "\n",
        "    # Load the dataset\n",
        "    X_train = load_data(dataPath)\n",
        "\n",
        "    # Rescale -1 to 1\n",
        "    X_train = X_train / 127\n",
        "\n",
        "    # Adversarial ground truths\n",
        "    valid = np.ones((batch_size,1,1))\n",
        "    fake = np.zeros((batch_size,1,1))\n",
        "    \n",
        "    g_loss_epochs = np.zeros((epochs, 1))\n",
        "    d_loss_epochs = np.zeros((epochs, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "      # ---------------------\n",
        "      #  Train Discriminator\n",
        "      # ---------------------\n",
        "\n",
        "      # Select a random half of images\n",
        "      idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "      imgs = X_train[idx]\n",
        "      imgs = np.array(imgs)\n",
        "      imgs = imgs.reshape(len(imgs),16,1)\n",
        "\n",
        "      # Sample noise and generate a batch of new images\n",
        "      noise = np.random.normal(0, 1, (batch_size,4,4))\n",
        "      gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "      # Train the discriminator (real classified as ones and generated as zeros)\n",
        "      d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "      d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "      # ---------------------\n",
        "      #  Train Generator\n",
        "      # ---------------------\n",
        "\n",
        "      # Train the generator (wants discriminator to mistake images as real)\n",
        "      g_loss = self.combined.train_on_batch(noise, valid)\n",
        "      \n",
        "      #save loss history\n",
        "      g_loss_epochs[epoch] = g_loss\n",
        "      d_loss_epochs[epoch] = d_loss[0]\n",
        "\n",
        "      # Plot the progress\n",
        "      print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "      # If at save interval => save generated image samples\n",
        "      if epoch % save_interval == 0:\n",
        "          self.generator.save(modelPath)\n",
        "    return g_loss_epochs, d_loss_epochs\n",
        "\n",
        "\n",
        "def predict_newSong(model):\n",
        "  random = np.random.normal(1, 1, (1,4,4))\n",
        "  newSong = model.predict(random)\n",
        "  for x in range(16):\n",
        "      newSong[0][x][0] = abs(newSong[0][x][0] * 11)\n",
        "      while(newSong[0][x][0] < 10):\n",
        "          newSong[0][x][0] = abs(newSong[0][x][0] * 10)\n",
        "      while(newSong[0][x][0] > 127):\n",
        "          newSong[0][x][0] = newSong[0][x][0] / 10\n",
        "  return newSong\n",
        "\n",
        "\n",
        "def generate_newMidFile(timingFilePath, resultPath, newSong):\n",
        "  timing = np.load(timingFilePath, allow_pickle=True)\n",
        "  count = 0\n",
        "  mid = MidiFile()\n",
        "  track = MidiTrack()\n",
        "  mid.tracks.append(track)\n",
        "  track2 = MidiTrack()\n",
        "  mid.tracks.append(track2)\n",
        "  track3 = MidiTrack()\n",
        "  mid.tracks.append(track3)\n",
        "  track4 = MidiTrack()\n",
        "  mid.tracks.append(track4)\n",
        "  octave = 12 * 6\n",
        "  t = randrange(len(timing))\n",
        "\n",
        "  track.append(Message('program_change', program=2,time=0))\n",
        "  track2.append(Message('program_change', program=2, time=0))\n",
        "  track3.append(Message('program_change', program=2,time=0))\n",
        "  track4.append(Message('program_change', program=2, time=0))\n",
        "      \n",
        "  for i in range(2):\n",
        "      track2.append(Message('note_on', note= 68, velocity=randrange(70,80), time=0))\n",
        "      track2.append(Message('note_off', note= 68, velocity=randrange(70,80), time=1920))\n",
        "      track3.append(Message('note_on', note= 64, velocity=randrange(70,80), time=0))\n",
        "      track3.append(Message('note_off', note= 64, velocity=randrange(70,80), time=1920))\n",
        "      track4.append(Message('note_on', note= 59, velocity=randrange(70,80), time=0))\n",
        "      track4.append(Message('note_off', note=59, velocity=randrange(70,80), time=1920))\n",
        "\n",
        "      track2.append(Message('note_on', note= 69, velocity=randrange(70,80), time=0))\n",
        "      track2.append(Message('note_off', note= 69, velocity=randrange(70,80), time=1920))\n",
        "      track3.append(Message('note_on', note= 66, velocity=randrange(70,80), time=0))\n",
        "      track3.append(Message('note_off', note= 66, velocity=randrange(70,80), time=1920))\n",
        "      track4.append(Message('note_on', note= 62, velocity=randrange(70,80), time=0))\n",
        "      track4.append(Message('note_off', note=62, velocity=randrange(70,80), time=1920))\n",
        "\n",
        "      track2.append(Message('note_on', note= 73, velocity=randrange(70,80), time=0))\n",
        "      track2.append(Message('note_off', note= 73, velocity=randrange(70,80), time=1920))\n",
        "      track3.append(Message('note_on', note= 68, velocity=randrange(70,80), time=0))\n",
        "      track3.append(Message('note_off', note= 68, velocity=randrange(70,80), time=1920))\n",
        "      track4.append(Message('note_on', note= 64, velocity=randrange(70,80), time=0))\n",
        "      track4.append(Message('note_off', note=64, velocity=randrange(70,80), time=1920))\n",
        "\n",
        "      track2.append(Message('note_on', note= 69, velocity=randrange(70,80), time=0))\n",
        "      track2.append(Message('note_off', note= 69, velocity=randrange(70,80), time=1920))\n",
        "      track3.append(Message('note_on', note= 66, velocity=randrange(70,80), time=0))\n",
        "      track3.append(Message('note_off', note= 66, velocity=randrange(70,80), time=1920))\n",
        "      track4.append(Message('note_on', note= 62, velocity=randrange(70,80), time=0))\n",
        "      track4.append(Message('note_off', note=62, velocity=randrange(70,80), time=1920))\n",
        "  for x in range(2):\n",
        "      count = 0\n",
        "      for i in range(16):\n",
        "          if(i == 0):\n",
        "              track.append(Message('note_on', note= octave + note_reg(int(newSong[0][i][0])), velocity=randrange(90,110), time=0))\n",
        "          else:\n",
        "              track.append(Message('note_on', note= octave + note_reg(int(newSong[0][i][0])), velocity=randrange(90,110), time=20))\n",
        "          track.append(Message('note_off', note= octave + note_reg(int(newSong[0][i][0])), velocity=randrange(90,110), time=timing[t].get(str(i))))\n",
        "          count = count + 1\n",
        "  mid.save(resultPath)\n",
        "\n",
        "\n",
        "def main():\n",
        "  inputPath = \"input/\"\n",
        "  dataPath = \"data/data.npy\"\n",
        "  read_inputFiles(inputPath, dataPath)\n",
        "\n",
        "  myGAN = GAN()\n",
        "  modelPath = \"data/GAN_generator.h5\"\n",
        "  g_loss, d_loss = myGAN.train(dataPath, modelPath, epochs=301, batch_size=128, save_interval=100)\n",
        "  model = load_model(modelPath)\n",
        "\n",
        "  newSong = predict_newSong(model)\n",
        "  timingFilePath = \"data/csp.npy\"\n",
        "  resultPath = \"data/newSong.mid\"\n",
        "  generate_newMidFile(timingFilePath, resultPath, newSong)\n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_6 (Bidirection (None, 16, 512)           528384    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 16, 512)           0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 16, 512)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 512)               1574912   \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 1, 512)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 1, 300)            153900    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 1, 300)            0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 1, 300)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 1, 300)            90300     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 1, 300)            0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1, 300)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 1, 300)            90300     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 1, 300)            0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 1, 300)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 1, 1)              301       \n",
            "=================================================================\n",
            "Total params: 2,438,097\n",
            "Trainable params: 2,438,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_8 (Bidirection (None, 4, 256)            136192    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 4, 256)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_3 (RepeatVecto (None, 16, 256)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 16, 256)           394240    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 16, 256)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 16, 256)           394240    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 16, 256)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 16, 256)           65792     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 16, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 16, 256)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 16, 1)             257       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 16, 1)             0         \n",
            "=================================================================\n",
            "Total params: 1,384,961\n",
            "Trainable params: 1,384,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "0 [D loss: 6.111023, acc.: 50.00%] [G loss: 0.991783]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "1 [D loss: 2.758212, acc.: 50.00%] [G loss: 0.989304]\n",
            "2 [D loss: 2.628768, acc.: 50.00%] [G loss: 0.987472]\n",
            "3 [D loss: 2.556256, acc.: 50.00%] [G loss: 0.985572]\n",
            "4 [D loss: 2.492525, acc.: 50.00%] [G loss: 0.983869]\n",
            "5 [D loss: 2.442429, acc.: 50.00%] [G loss: 0.981483]\n",
            "6 [D loss: 2.396456, acc.: 50.00%] [G loss: 0.978624]\n",
            "7 [D loss: 2.336751, acc.: 50.00%] [G loss: 0.974779]\n",
            "8 [D loss: 2.275735, acc.: 50.00%] [G loss: 0.970716]\n",
            "9 [D loss: 2.209068, acc.: 50.00%] [G loss: 0.964231]\n",
            "10 [D loss: 2.151775, acc.: 50.00%] [G loss: 0.954976]\n",
            "11 [D loss: 2.082117, acc.: 50.00%] [G loss: 0.944746]\n",
            "12 [D loss: 2.014865, acc.: 50.00%] [G loss: 0.926387]\n",
            "13 [D loss: 1.937167, acc.: 50.00%] [G loss: 0.910268]\n",
            "14 [D loss: 1.875884, acc.: 50.00%] [G loss: 0.887160]\n",
            "15 [D loss: 1.800057, acc.: 50.00%] [G loss: 0.869133]\n",
            "16 [D loss: 1.728433, acc.: 50.00%] [G loss: 0.855163]\n",
            "17 [D loss: 1.633062, acc.: 50.00%] [G loss: 0.876873]\n",
            "18 [D loss: 1.532728, acc.: 50.00%] [G loss: 0.910138]\n",
            "19 [D loss: 1.452904, acc.: 50.00%] [G loss: 0.903585]\n",
            "20 [D loss: 1.342338, acc.: 50.00%] [G loss: 0.925610]\n",
            "21 [D loss: 1.230059, acc.: 50.00%] [G loss: 0.897525]\n",
            "22 [D loss: 1.125919, acc.: 50.00%] [G loss: 0.889158]\n",
            "23 [D loss: 1.039176, acc.: 50.00%] [G loss: 0.861219]\n",
            "24 [D loss: 0.947328, acc.: 50.00%] [G loss: 0.807485]\n",
            "25 [D loss: 0.883747, acc.: 50.00%] [G loss: 0.777481]\n",
            "26 [D loss: 0.805218, acc.: 49.61%] [G loss: 0.670212]\n",
            "27 [D loss: 0.736931, acc.: 49.22%] [G loss: 0.656652]\n",
            "28 [D loss: 0.694925, acc.: 46.09%] [G loss: 0.582505]\n",
            "29 [D loss: 0.684376, acc.: 46.09%] [G loss: 0.479989]\n",
            "30 [D loss: 0.707785, acc.: 46.48%] [G loss: 0.406490]\n",
            "31 [D loss: 0.752272, acc.: 40.62%] [G loss: 0.329520]\n",
            "32 [D loss: 0.770861, acc.: 39.06%] [G loss: 0.309087]\n",
            "33 [D loss: 0.775008, acc.: 41.02%] [G loss: 0.323255]\n",
            "34 [D loss: 0.733848, acc.: 48.05%] [G loss: 0.321866]\n",
            "35 [D loss: 0.752742, acc.: 43.75%] [G loss: 0.334217]\n",
            "36 [D loss: 0.737779, acc.: 48.05%] [G loss: 0.342976]\n",
            "37 [D loss: 0.771360, acc.: 44.53%] [G loss: 0.324594]\n",
            "38 [D loss: 0.748416, acc.: 43.36%] [G loss: 0.325442]\n",
            "39 [D loss: 0.761785, acc.: 39.06%] [G loss: 0.337752]\n",
            "40 [D loss: 0.744076, acc.: 42.19%] [G loss: 0.305846]\n",
            "41 [D loss: 0.739094, acc.: 46.09%] [G loss: 0.323876]\n",
            "42 [D loss: 0.765362, acc.: 39.45%] [G loss: 0.322379]\n",
            "43 [D loss: 0.735804, acc.: 47.66%] [G loss: 0.314893]\n",
            "44 [D loss: 0.740848, acc.: 45.70%] [G loss: 0.313112]\n",
            "45 [D loss: 0.739029, acc.: 48.44%] [G loss: 0.309180]\n",
            "46 [D loss: 0.769145, acc.: 38.67%] [G loss: 0.325202]\n",
            "47 [D loss: 0.755229, acc.: 44.14%] [G loss: 0.318255]\n",
            "48 [D loss: 0.757006, acc.: 41.41%] [G loss: 0.326902]\n",
            "49 [D loss: 0.750502, acc.: 43.75%] [G loss: 0.322471]\n",
            "50 [D loss: 0.750108, acc.: 41.80%] [G loss: 0.299833]\n",
            "51 [D loss: 0.736020, acc.: 45.70%] [G loss: 0.338673]\n",
            "52 [D loss: 0.746960, acc.: 44.53%] [G loss: 0.317063]\n",
            "53 [D loss: 0.744626, acc.: 43.36%] [G loss: 0.312445]\n",
            "54 [D loss: 0.750757, acc.: 47.66%] [G loss: 0.300420]\n",
            "55 [D loss: 0.730994, acc.: 42.97%] [G loss: 0.321537]\n",
            "56 [D loss: 0.753661, acc.: 45.70%] [G loss: 0.292735]\n",
            "57 [D loss: 0.738843, acc.: 43.75%] [G loss: 0.303810]\n",
            "58 [D loss: 0.748045, acc.: 40.62%] [G loss: 0.310294]\n",
            "59 [D loss: 0.757769, acc.: 41.41%] [G loss: 0.319276]\n",
            "60 [D loss: 0.750826, acc.: 40.23%] [G loss: 0.299575]\n",
            "61 [D loss: 0.757297, acc.: 42.97%] [G loss: 0.321399]\n",
            "62 [D loss: 0.731062, acc.: 45.31%] [G loss: 0.305683]\n",
            "63 [D loss: 0.769225, acc.: 35.16%] [G loss: 0.301878]\n",
            "64 [D loss: 0.737563, acc.: 43.75%] [G loss: 0.321876]\n",
            "65 [D loss: 0.749467, acc.: 43.36%] [G loss: 0.322017]\n",
            "66 [D loss: 0.750474, acc.: 43.75%] [G loss: 0.319612]\n",
            "67 [D loss: 0.750432, acc.: 42.19%] [G loss: 0.304067]\n",
            "68 [D loss: 0.754053, acc.: 39.06%] [G loss: 0.306133]\n",
            "69 [D loss: 0.757773, acc.: 40.62%] [G loss: 0.318015]\n",
            "70 [D loss: 0.735603, acc.: 45.31%] [G loss: 0.326104]\n",
            "71 [D loss: 0.743791, acc.: 46.88%] [G loss: 0.320340]\n",
            "72 [D loss: 0.762395, acc.: 36.72%] [G loss: 0.336371]\n",
            "73 [D loss: 0.754388, acc.: 45.31%] [G loss: 0.318391]\n",
            "74 [D loss: 0.758072, acc.: 38.28%] [G loss: 0.310102]\n",
            "75 [D loss: 0.739894, acc.: 47.66%] [G loss: 0.327478]\n",
            "76 [D loss: 0.745394, acc.: 41.80%] [G loss: 0.317985]\n",
            "77 [D loss: 0.760666, acc.: 38.67%] [G loss: 0.317541]\n",
            "78 [D loss: 0.732395, acc.: 47.66%] [G loss: 0.313102]\n",
            "79 [D loss: 0.747153, acc.: 41.02%] [G loss: 0.307293]\n",
            "80 [D loss: 0.756238, acc.: 39.84%] [G loss: 0.297035]\n",
            "81 [D loss: 0.743061, acc.: 46.48%] [G loss: 0.310412]\n",
            "82 [D loss: 0.753672, acc.: 41.80%] [G loss: 0.303932]\n",
            "83 [D loss: 0.753072, acc.: 41.80%] [G loss: 0.321161]\n",
            "84 [D loss: 0.755995, acc.: 39.06%] [G loss: 0.324130]\n",
            "85 [D loss: 0.767168, acc.: 40.62%] [G loss: 0.332870]\n",
            "86 [D loss: 0.748676, acc.: 42.97%] [G loss: 0.325838]\n",
            "87 [D loss: 0.754220, acc.: 40.23%] [G loss: 0.316040]\n",
            "88 [D loss: 0.749732, acc.: 39.84%] [G loss: 0.316281]\n",
            "89 [D loss: 0.763960, acc.: 42.19%] [G loss: 0.327656]\n",
            "90 [D loss: 0.742383, acc.: 44.53%] [G loss: 0.322781]\n",
            "91 [D loss: 0.736594, acc.: 44.53%] [G loss: 0.304067]\n",
            "92 [D loss: 0.760456, acc.: 39.84%] [G loss: 0.302975]\n",
            "93 [D loss: 0.735152, acc.: 42.19%] [G loss: 0.317115]\n",
            "94 [D loss: 0.750306, acc.: 44.14%] [G loss: 0.304372]\n",
            "95 [D loss: 0.744728, acc.: 40.62%] [G loss: 0.304817]\n",
            "96 [D loss: 0.740623, acc.: 44.92%] [G loss: 0.308003]\n",
            "97 [D loss: 0.738646, acc.: 44.53%] [G loss: 0.324648]\n",
            "98 [D loss: 0.745295, acc.: 43.36%] [G loss: 0.305628]\n",
            "99 [D loss: 0.765666, acc.: 39.45%] [G loss: 0.306911]\n",
            "100 [D loss: 0.736738, acc.: 48.44%] [G loss: 0.306357]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "101 [D loss: 0.766955, acc.: 38.28%] [G loss: 0.304119]\n",
            "102 [D loss: 0.728773, acc.: 45.70%] [G loss: 0.308426]\n",
            "103 [D loss: 0.746680, acc.: 41.02%] [G loss: 0.305782]\n",
            "104 [D loss: 0.744763, acc.: 44.14%] [G loss: 0.305597]\n",
            "105 [D loss: 0.730065, acc.: 46.48%] [G loss: 0.299750]\n",
            "106 [D loss: 0.736390, acc.: 44.53%] [G loss: 0.301642]\n",
            "107 [D loss: 0.754094, acc.: 41.41%] [G loss: 0.312870]\n",
            "108 [D loss: 0.732421, acc.: 48.83%] [G loss: 0.306858]\n",
            "109 [D loss: 0.746978, acc.: 42.19%] [G loss: 0.317642]\n",
            "110 [D loss: 0.754327, acc.: 41.41%] [G loss: 0.316106]\n",
            "111 [D loss: 0.736588, acc.: 44.92%] [G loss: 0.303019]\n",
            "112 [D loss: 0.735375, acc.: 45.70%] [G loss: 0.312519]\n",
            "113 [D loss: 0.733250, acc.: 40.23%] [G loss: 0.315445]\n",
            "114 [D loss: 0.742009, acc.: 40.62%] [G loss: 0.306985]\n",
            "115 [D loss: 0.748311, acc.: 40.23%] [G loss: 0.320703]\n",
            "116 [D loss: 0.756072, acc.: 41.02%] [G loss: 0.300578]\n",
            "117 [D loss: 0.750903, acc.: 41.41%] [G loss: 0.305216]\n",
            "118 [D loss: 0.729874, acc.: 44.92%] [G loss: 0.298294]\n",
            "119 [D loss: 0.765893, acc.: 42.58%] [G loss: 0.314700]\n",
            "120 [D loss: 0.759831, acc.: 41.80%] [G loss: 0.310315]\n",
            "121 [D loss: 0.736355, acc.: 44.53%] [G loss: 0.315428]\n",
            "122 [D loss: 0.782295, acc.: 37.89%] [G loss: 0.318795]\n",
            "123 [D loss: 0.761271, acc.: 42.58%] [G loss: 0.324920]\n",
            "124 [D loss: 0.734048, acc.: 41.80%] [G loss: 0.305948]\n",
            "125 [D loss: 0.751755, acc.: 42.58%] [G loss: 0.306148]\n",
            "126 [D loss: 0.738033, acc.: 44.92%] [G loss: 0.295960]\n",
            "127 [D loss: 0.734856, acc.: 46.09%] [G loss: 0.307753]\n",
            "128 [D loss: 0.737422, acc.: 43.75%] [G loss: 0.308212]\n",
            "129 [D loss: 0.748670, acc.: 44.14%] [G loss: 0.310332]\n",
            "130 [D loss: 0.733916, acc.: 46.88%] [G loss: 0.321554]\n",
            "131 [D loss: 0.754460, acc.: 40.23%] [G loss: 0.308325]\n",
            "132 [D loss: 0.742056, acc.: 46.09%] [G loss: 0.306465]\n",
            "133 [D loss: 0.759664, acc.: 39.84%] [G loss: 0.305044]\n",
            "134 [D loss: 0.739823, acc.: 40.23%] [G loss: 0.315953]\n",
            "135 [D loss: 0.732175, acc.: 42.58%] [G loss: 0.313829]\n",
            "136 [D loss: 0.745985, acc.: 42.19%] [G loss: 0.303949]\n",
            "137 [D loss: 0.745901, acc.: 40.23%] [G loss: 0.310524]\n",
            "138 [D loss: 0.740056, acc.: 41.41%] [G loss: 0.300730]\n",
            "139 [D loss: 0.743524, acc.: 42.58%] [G loss: 0.314403]\n",
            "140 [D loss: 0.737977, acc.: 44.14%] [G loss: 0.303092]\n",
            "141 [D loss: 0.762801, acc.: 44.53%] [G loss: 0.316181]\n",
            "142 [D loss: 0.750809, acc.: 42.19%] [G loss: 0.320617]\n",
            "143 [D loss: 0.747808, acc.: 43.36%] [G loss: 0.311149]\n",
            "144 [D loss: 0.767456, acc.: 40.62%] [G loss: 0.313390]\n",
            "145 [D loss: 0.722444, acc.: 46.88%] [G loss: 0.306842]\n",
            "146 [D loss: 0.739969, acc.: 44.14%] [G loss: 0.294356]\n",
            "147 [D loss: 0.752479, acc.: 43.75%] [G loss: 0.308848]\n",
            "148 [D loss: 0.755194, acc.: 40.23%] [G loss: 0.310620]\n",
            "149 [D loss: 0.716264, acc.: 46.48%] [G loss: 0.306674]\n",
            "150 [D loss: 0.740606, acc.: 45.70%] [G loss: 0.301824]\n",
            "151 [D loss: 0.739391, acc.: 43.75%] [G loss: 0.298749]\n",
            "152 [D loss: 0.750473, acc.: 41.41%] [G loss: 0.290714]\n",
            "153 [D loss: 0.740115, acc.: 48.83%] [G loss: 0.297437]\n",
            "154 [D loss: 0.739515, acc.: 44.53%] [G loss: 0.303974]\n",
            "155 [D loss: 0.716290, acc.: 50.78%] [G loss: 0.305937]\n",
            "156 [D loss: 0.749818, acc.: 40.23%] [G loss: 0.302204]\n",
            "157 [D loss: 0.736294, acc.: 44.14%] [G loss: 0.318400]\n",
            "158 [D loss: 0.743377, acc.: 42.97%] [G loss: 0.296556]\n",
            "159 [D loss: 0.732510, acc.: 45.70%] [G loss: 0.308428]\n",
            "160 [D loss: 0.740985, acc.: 42.58%] [G loss: 0.303290]\n",
            "161 [D loss: 0.717832, acc.: 46.88%] [G loss: 0.297303]\n",
            "162 [D loss: 0.746140, acc.: 42.97%] [G loss: 0.297694]\n",
            "163 [D loss: 0.750735, acc.: 39.06%] [G loss: 0.308277]\n",
            "164 [D loss: 0.736868, acc.: 47.66%] [G loss: 0.302416]\n",
            "165 [D loss: 0.737403, acc.: 41.80%] [G loss: 0.324818]\n",
            "166 [D loss: 0.733447, acc.: 42.19%] [G loss: 0.308848]\n",
            "167 [D loss: 0.738625, acc.: 39.84%] [G loss: 0.296711]\n",
            "168 [D loss: 0.736248, acc.: 44.92%] [G loss: 0.294766]\n",
            "169 [D loss: 0.738040, acc.: 48.44%] [G loss: 0.285095]\n",
            "170 [D loss: 0.733406, acc.: 47.27%] [G loss: 0.316256]\n",
            "171 [D loss: 0.739317, acc.: 46.09%] [G loss: 0.294765]\n",
            "172 [D loss: 0.735376, acc.: 45.31%] [G loss: 0.299885]\n",
            "173 [D loss: 0.743293, acc.: 44.14%] [G loss: 0.304506]\n",
            "174 [D loss: 0.741297, acc.: 44.14%] [G loss: 0.314220]\n",
            "175 [D loss: 0.752490, acc.: 38.67%] [G loss: 0.302124]\n",
            "176 [D loss: 0.731968, acc.: 43.75%] [G loss: 0.289970]\n",
            "177 [D loss: 0.724552, acc.: 45.31%] [G loss: 0.313416]\n",
            "178 [D loss: 0.744433, acc.: 42.19%] [G loss: 0.296333]\n",
            "179 [D loss: 0.733716, acc.: 41.80%] [G loss: 0.303232]\n",
            "180 [D loss: 0.733304, acc.: 43.36%] [G loss: 0.301850]\n",
            "181 [D loss: 0.723536, acc.: 42.58%] [G loss: 0.315806]\n",
            "182 [D loss: 0.735542, acc.: 43.75%] [G loss: 0.297605]\n",
            "183 [D loss: 0.728024, acc.: 44.14%] [G loss: 0.296257]\n",
            "184 [D loss: 0.739529, acc.: 45.31%] [G loss: 0.317237]\n",
            "185 [D loss: 0.741428, acc.: 42.58%] [G loss: 0.289969]\n",
            "186 [D loss: 0.745317, acc.: 45.31%] [G loss: 0.301478]\n",
            "187 [D loss: 0.733954, acc.: 44.53%] [G loss: 0.295635]\n",
            "188 [D loss: 0.746237, acc.: 44.53%] [G loss: 0.305619]\n",
            "189 [D loss: 0.758555, acc.: 40.62%] [G loss: 0.307246]\n",
            "190 [D loss: 0.740643, acc.: 44.53%] [G loss: 0.309568]\n",
            "191 [D loss: 0.741256, acc.: 41.02%] [G loss: 0.308865]\n",
            "192 [D loss: 0.768022, acc.: 41.02%] [G loss: 0.301231]\n",
            "193 [D loss: 0.713014, acc.: 47.27%] [G loss: 0.300263]\n",
            "194 [D loss: 0.741774, acc.: 44.53%] [G loss: 0.306226]\n",
            "195 [D loss: 0.737660, acc.: 44.53%] [G loss: 0.307619]\n",
            "196 [D loss: 0.746852, acc.: 43.36%] [G loss: 0.315268]\n",
            "197 [D loss: 0.735084, acc.: 44.14%] [G loss: 0.305818]\n",
            "198 [D loss: 0.741628, acc.: 41.41%] [G loss: 0.312370]\n",
            "199 [D loss: 0.747233, acc.: 41.02%] [G loss: 0.299750]\n",
            "200 [D loss: 0.730112, acc.: 45.70%] [G loss: 0.316016]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "201 [D loss: 0.753661, acc.: 40.23%] [G loss: 0.314967]\n",
            "202 [D loss: 0.732733, acc.: 42.19%] [G loss: 0.309470]\n",
            "203 [D loss: 0.751765, acc.: 43.36%] [G loss: 0.307743]\n",
            "204 [D loss: 0.721524, acc.: 49.61%] [G loss: 0.296317]\n",
            "205 [D loss: 0.733889, acc.: 45.70%] [G loss: 0.315152]\n",
            "206 [D loss: 0.736375, acc.: 45.31%] [G loss: 0.309611]\n",
            "207 [D loss: 0.724479, acc.: 44.53%] [G loss: 0.303109]\n",
            "208 [D loss: 0.729697, acc.: 44.92%] [G loss: 0.300187]\n",
            "209 [D loss: 0.741705, acc.: 46.09%] [G loss: 0.294247]\n",
            "210 [D loss: 0.736464, acc.: 45.31%] [G loss: 0.293197]\n",
            "211 [D loss: 0.735966, acc.: 43.75%] [G loss: 0.314598]\n",
            "212 [D loss: 0.738772, acc.: 43.75%] [G loss: 0.307201]\n",
            "213 [D loss: 0.727346, acc.: 46.48%] [G loss: 0.308225]\n",
            "214 [D loss: 0.752830, acc.: 41.41%] [G loss: 0.309753]\n",
            "215 [D loss: 0.736507, acc.: 45.70%] [G loss: 0.304929]\n",
            "216 [D loss: 0.726369, acc.: 45.31%] [G loss: 0.310753]\n",
            "217 [D loss: 0.720942, acc.: 46.88%] [G loss: 0.299114]\n",
            "218 [D loss: 0.732413, acc.: 46.88%] [G loss: 0.304946]\n",
            "219 [D loss: 0.737461, acc.: 43.75%] [G loss: 0.324708]\n",
            "220 [D loss: 0.738471, acc.: 43.36%] [G loss: 0.312409]\n",
            "221 [D loss: 0.734285, acc.: 49.61%] [G loss: 0.289003]\n",
            "222 [D loss: 0.747045, acc.: 43.36%] [G loss: 0.293227]\n",
            "223 [D loss: 0.734529, acc.: 44.14%] [G loss: 0.286417]\n",
            "224 [D loss: 0.762624, acc.: 38.67%] [G loss: 0.290836]\n",
            "225 [D loss: 0.730593, acc.: 48.44%] [G loss: 0.301605]\n",
            "226 [D loss: 0.733991, acc.: 41.41%] [G loss: 0.290716]\n",
            "227 [D loss: 0.730623, acc.: 46.48%] [G loss: 0.292593]\n",
            "228 [D loss: 0.752820, acc.: 38.67%] [G loss: 0.300612]\n",
            "229 [D loss: 0.736769, acc.: 43.36%] [G loss: 0.317382]\n",
            "230 [D loss: 0.721141, acc.: 46.09%] [G loss: 0.290787]\n",
            "231 [D loss: 0.744590, acc.: 44.14%] [G loss: 0.299058]\n",
            "232 [D loss: 0.750719, acc.: 41.41%] [G loss: 0.301806]\n",
            "233 [D loss: 0.734406, acc.: 45.31%] [G loss: 0.311108]\n",
            "234 [D loss: 0.740886, acc.: 41.80%] [G loss: 0.300670]\n",
            "235 [D loss: 0.736393, acc.: 45.31%] [G loss: 0.290393]\n",
            "236 [D loss: 0.729882, acc.: 48.05%] [G loss: 0.299120]\n",
            "237 [D loss: 0.756917, acc.: 40.62%] [G loss: 0.294318]\n",
            "238 [D loss: 0.732182, acc.: 45.70%] [G loss: 0.279109]\n",
            "239 [D loss: 0.762018, acc.: 42.19%] [G loss: 0.292677]\n",
            "240 [D loss: 0.718490, acc.: 49.22%] [G loss: 0.295673]\n",
            "241 [D loss: 0.717072, acc.: 47.66%] [G loss: 0.299359]\n",
            "242 [D loss: 0.732421, acc.: 43.75%] [G loss: 0.293383]\n",
            "243 [D loss: 0.730111, acc.: 44.53%] [G loss: 0.289748]\n",
            "244 [D loss: 0.739833, acc.: 48.05%] [G loss: 0.311366]\n",
            "245 [D loss: 0.749175, acc.: 40.23%] [G loss: 0.306419]\n",
            "246 [D loss: 0.724874, acc.: 44.92%] [G loss: 0.302397]\n",
            "247 [D loss: 0.722527, acc.: 49.22%] [G loss: 0.290797]\n",
            "248 [D loss: 0.755976, acc.: 39.84%] [G loss: 0.317041]\n",
            "249 [D loss: 0.719247, acc.: 47.27%] [G loss: 0.304920]\n",
            "250 [D loss: 0.722361, acc.: 45.70%] [G loss: 0.295381]\n",
            "251 [D loss: 0.740633, acc.: 41.80%] [G loss: 0.299553]\n",
            "252 [D loss: 0.738121, acc.: 43.36%] [G loss: 0.291446]\n",
            "253 [D loss: 0.739550, acc.: 43.36%] [G loss: 0.289175]\n",
            "254 [D loss: 0.767298, acc.: 41.80%] [G loss: 0.291985]\n",
            "255 [D loss: 0.728337, acc.: 44.14%] [G loss: 0.299311]\n",
            "256 [D loss: 0.742928, acc.: 43.36%] [G loss: 0.292770]\n",
            "257 [D loss: 0.740601, acc.: 43.36%] [G loss: 0.296824]\n",
            "258 [D loss: 0.743098, acc.: 44.53%] [G loss: 0.311732]\n",
            "259 [D loss: 0.755682, acc.: 39.45%] [G loss: 0.301345]\n",
            "260 [D loss: 0.732161, acc.: 46.88%] [G loss: 0.297080]\n",
            "261 [D loss: 0.738269, acc.: 42.58%] [G loss: 0.306659]\n",
            "262 [D loss: 0.753498, acc.: 39.84%] [G loss: 0.314875]\n",
            "263 [D loss: 0.750318, acc.: 41.41%] [G loss: 0.300311]\n",
            "264 [D loss: 0.726210, acc.: 46.88%] [G loss: 0.284823]\n",
            "265 [D loss: 0.749876, acc.: 41.02%] [G loss: 0.292385]\n",
            "266 [D loss: 0.747897, acc.: 39.45%] [G loss: 0.306672]\n",
            "267 [D loss: 0.747127, acc.: 39.45%] [G loss: 0.292985]\n",
            "268 [D loss: 0.735615, acc.: 47.27%] [G loss: 0.315148]\n",
            "269 [D loss: 0.751015, acc.: 37.11%] [G loss: 0.311050]\n",
            "270 [D loss: 0.732326, acc.: 43.36%] [G loss: 0.302564]\n",
            "271 [D loss: 0.737208, acc.: 46.48%] [G loss: 0.306897]\n",
            "272 [D loss: 0.735158, acc.: 42.19%] [G loss: 0.303819]\n",
            "273 [D loss: 0.745319, acc.: 41.02%] [G loss: 0.299221]\n",
            "274 [D loss: 0.744506, acc.: 38.28%] [G loss: 0.307093]\n",
            "275 [D loss: 0.748159, acc.: 39.06%] [G loss: 0.320114]\n",
            "276 [D loss: 0.729533, acc.: 46.09%] [G loss: 0.296644]\n",
            "277 [D loss: 0.735131, acc.: 47.27%] [G loss: 0.299765]\n",
            "278 [D loss: 0.725932, acc.: 44.14%] [G loss: 0.296499]\n",
            "279 [D loss: 0.741818, acc.: 44.53%] [G loss: 0.309318]\n",
            "280 [D loss: 0.745279, acc.: 40.62%] [G loss: 0.299618]\n",
            "281 [D loss: 0.736900, acc.: 46.88%] [G loss: 0.298947]\n",
            "282 [D loss: 0.729225, acc.: 44.92%] [G loss: 0.298462]\n",
            "283 [D loss: 0.741506, acc.: 42.97%] [G loss: 0.306167]\n",
            "284 [D loss: 0.747915, acc.: 40.62%] [G loss: 0.310250]\n",
            "285 [D loss: 0.733159, acc.: 41.02%] [G loss: 0.308286]\n",
            "286 [D loss: 0.730542, acc.: 46.48%] [G loss: 0.300405]\n",
            "287 [D loss: 0.746738, acc.: 39.45%] [G loss: 0.302657]\n",
            "288 [D loss: 0.733169, acc.: 42.97%] [G loss: 0.299266]\n",
            "289 [D loss: 0.749443, acc.: 43.75%] [G loss: 0.308868]\n",
            "290 [D loss: 0.742194, acc.: 46.88%] [G loss: 0.306413]\n",
            "291 [D loss: 0.740955, acc.: 40.62%] [G loss: 0.304581]\n",
            "292 [D loss: 0.748626, acc.: 43.75%] [G loss: 0.314273]\n",
            "293 [D loss: 0.741890, acc.: 39.84%] [G loss: 0.308440]\n",
            "294 [D loss: 0.765343, acc.: 38.67%] [G loss: 0.284231]\n",
            "295 [D loss: 0.730435, acc.: 44.92%] [G loss: 0.311193]\n",
            "296 [D loss: 0.742929, acc.: 42.97%] [G loss: 0.292254]\n",
            "297 [D loss: 0.769161, acc.: 40.62%] [G loss: 0.308007]\n",
            "298 [D loss: 0.729045, acc.: 47.27%] [G loss: 0.307436]\n",
            "299 [D loss: 0.734782, acc.: 45.31%] [G loss: 0.312402]\n",
            "300 [D loss: 0.746685, acc.: 43.75%] [G loss: 0.312882]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}